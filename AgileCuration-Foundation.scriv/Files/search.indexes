<?xml version="1.0" encoding="UTF-8"?>
<SearchIndexes Version="1.0">
    <Documents>
        <Document ID="10">
            <Title>Authors Biographical Statement</Title>
            <Text># Biographical Statement</Text>
        </Document>
        <Document ID="15">
            <Title>Untitled</Title>
        </Document>
        <Document ID="3">
            <Title>Front Matter</Title>
            <Text># Title
Agile Data Curation as a Diversity of Practices Grounded in Shared Values and Principles

# Authors
Karl Kent Benedict\
W. Christopher Lenhardt\
Joshua Young

# Author Affiliations
University of New Mexico\
Renaissance Computing Institute (RENCI)\
Unidata

# Corresponding Author's Email Address
kbene@unm.edu

</Text>
        </Document>
        <Document ID="11">
            <Title>Conclusion</Title>
            <Text># Conclusions

These are our conclusions</Text>
        </Document>
        <Document ID="16">
            <Title>Generated References</Title>
            <Text>Akers, K.G., Doty, J., 2013. Disciplinary differences in faculty research data management practices and perspectives. International Journal of Digital Curation 8, 5–26. doi:10.2218/ijdc.v8i2.263
Availability of data &amp; materials : Authors &amp; referees @ npg [WWW Document], 2016. [WWW Document]. URL http://www.nature.com/authors/policies/availability.html (accessed 10.30.16).
Ball, A., 2012. Review of data management lifecycle models.
Executive Summary: Data Growth, Business Opportunities, and the IT Imperatives | The Digital Universe of Opportunities: Rich Data and the Increasing Value of the Internet of Things [WWW Document], 2016. [WWW Document]. URL http://www.emc.com/leadership/digital-universe/2014iview/executive-summary.htm (accessed 10.31.16).
HEASARC Data/Usage Statistics [WWW Document], 2016. [WWW Document]. URL https://heasarc.gsfc.nasa.gov/docs/heasarc/stats/stats.html#arch_data (accessed 10.31.16).
Information Systems, W.G. on, Services Data, D.S.I.G., 2011. Data Lifecycle Models and Concepts Version 1.0.
Kennan, M.A., Markauskaite, L., 2015. Research Data Management Practices: A Snapshot in Time. International Journal of Digital Curation 10, 69–95. doi:10.2218/ijdc.v10i2.329
Kervin, K., Michener, W., Cook, R., 2013. Common Errors in Ecological Data Sharing. Journal of eScience Librarianship. doi:10.7191/jeslib.2013.1024
Möller, K., 2013. Lifecycle models of data-centric systems and domains. Semantic Web 4, 67–88.
Obama, B., 2013. Executive Order 13642 - Making Open and Machine Readable the New Default for Government Information. Federal Register 78, 28111–93.
Obama, B., 2012. 77 FR 32391: Building a 21st Century Digital Government.
Obama, B., 2009. Transparency and Open Government.
Office of Management and Budget (OMB), 2013. Memorandum for the Heads of Excutive Departments and Agencies - Open Data Policy – Managing Information as an Asset. M-13-13.
Office of Management and Budget (OMB), 2012. Digital government : Building a 21st century platform to better serve the American people. [Washington, D.C.] : [Washington, D.C.] :
Office of Management and Budget (OMB), 2009. Memorandum for the Heads of Executive Departments and Agencies - Open Government Directive. M-10-06.
Park, E.G., 2016. Session Two: OAIS Model &amp; Digital Curation Lifecycle Model.
Public Library of Science (PLOS), 2016. Data Availability [WWW Document]. URL http://journals.plos.org/plosone/s/data-availability (accessed 10.30.16).
Tenopir, C., Allard, S., Douglass, K., Aydinoglu, A.U., Wu, L., Read, E., Manoff, M., Frame, M., 2011. Data Sharing by Scientists: Practices and Perceptions. PLoS ONE 6, e21101. doi:10.1371/journal.pone.0021101
Vines, T.H., Albert, A.Y.K., Andrew, R.L., Débarre, F., Bock, D.G., Franklin, M.T., Gilbert, K.J., Moore, J.-S., Renaut, S., Rennison, D.J., 2014. The Availability of Research Data Declines Rapidly with Article Age. Current Biology 24, 94–97. doi:10.1016/j.cub.2013.11.014
White, H.C., 2010. Considering Personal Organization: Metadata Practices of Scientists. Journal of Library Metadata 10, 156–172. doi:10.1080/19386389.2010.506396
</Text>
        </Document>
        <Document ID="4">
            <Title>Overview</Title>
            <Text># Overview

The challenges that must be addressed by current research data management and curation processes and strategies consist of a combination of established practices that are not compatible with increasing complexity in the data management landscape at the project level; increasing expectations by sponsors, publishers, and institutions relating to data management and curation; and rapid growth in the volume, variety and velocity (three dimensions commonly used to define "big data") of data generated by and used in research. In combination these challenges translate into an increasing need to develop effective data management and curation strategies that align with a set of shared values and principles that inform management and curation objectives, and implement processes that are well documented and portable across specific data management projects. 

The concept of *agile data curation* outlined in this paper represents an effort by the authors to develop a conceptual model for data management and curation that extends beyond the linear or cyclical model represented by the many data lifecycle models that have been developed [@ball_review_2012; @park_session_2016; @moller_lifecycle_2013; @working_group_on_information_systems_and_services_data_data_stewardship_interest_group_data_2011]. These lifecycle models have been created to define processes that are more structured than the commonly used ad-hoc or minimally designed research processes that are not explicitly developed to meet the full arc of activities that meet the needs of both the current research activity *and* those of future users of the data products generated by that activity [@kervin_common_2013;@white_considering_2010;@tenopir_data_2011;@akers_disciplinary_2013;@kennan_research_2015;@vines_availability_2014]. 

In response to this problem of under-design and with the increasing recognition of the value of research data products for assessment, replication, validation, and extension of research, a variety of requirements have been put in place by sponsors [@office_of_management_and_budget_omb_digital_2012;@office_of_management_and_budget_omb_memorandum_2013;@office_of_management_and_budget_omb_memorandum_2009;@obama_77_2012;@obama_executive_2013;@obama_transparency_2009] and publishers [@_availability_2016; @public_library_of_science_plos_data_2016 ] for planning for and executing effective data management, sharing, and curation. While these requirements have resulted in more explicit documentation of *plans* for data curation and management, it remains unclear what impact they are having on *practice*. 

While the increasing requirements for planning and execution of systematic data management and curation have resulted in additional attention to these topics, there has not been a corresponding increase in funding in support of these activities. The challenge of fitting these required management and curation activities within existing funds is compounded by the continuing (often characterized as exponential) growth [@turner_executive_2016; @national_aeronautics_and_space_administration_nasa_heasarc_2016] in created, managed and requested data within those limited resources. These increasing demands within a consistently resource constrained environment increase the value of developing data management and curation objectives and strategies that are likely to maximize the current and future value of research data within available resources. 

Given this context, the authors have (with contributions from participants in workshops and meeting sessions held over the past two years in multiple venues) been considering the agile software development movement [@beck_manifesto_2001] as a source of inspiration for the development of a conceptual model for *agile data curation* that balances the needs for robust documentation and engineered solutions with a development cycle that is designed for incremental delivery of value  through an iterative development and investment process. From the discussions held with researchers and data managers participating in meetings of the Federation of Earth Science Information Partners (ESIP), American Geophysical Union (AGU), the Research Data Alliance (RDA), and SciDataCon the authors have had an opportunity to explore and refine some of the key concepts relating to agile data curation as it is both similar and dissimilar from agile software development. 

Figure @fig:continuum illustrates a number of the common and different characteristics that have been identified through the author’s review of the characteristics that may be ascribed to the ends of the continuum between highly designed/engineered processes and ad-hoc processes in both software development and data curation. 

![Illustration comparing software development and data curation activities along a continuum between *engineered* and *ad-hoc* highlighting a range of characteristics associated with with each activity, and the mid-point along the continuum where an agile approach can hopefully achieve a balance between the two extremes.](agileComparison-01.png){#fig:continuum}







Following the model developed by the agile software development communityThe set of values and principles developed by members of the software development community around the concept of *agile software development* provides a potential framework from which a set of agile data curation and management values and principles can be derived. Once a set of values and principles have been developed the community of research data producers and consumers is in a position to develop and use practices that are informed by those principles. 

The objective of this paper is to propose^[link to a web site where community input can be collected and collated into something like the *Manifesto*] a set of *agile data curation* values and principles that parallel those developed by members of the software development community, but reflect the distinctive characteristics and challenges posed by the research data process and its products. 

* Continuum from "Engineered" &lt;==&gt; "Agile" &lt;==&gt; "Ad-hoc"
	* Technical debt as another dimension for characterizing 
	* Dimensions to think about:
		* Required Formats
		* Required data schemas
		* Required file nameing conventions schemas
		* Required metadata/documentation content
		* Required metadata standards
		* Approvals required
* Recognize cost of capture/creation, management, sharing and preservation and build prioritization into decision making about what products/parameters are maintained within the system. 
</Text>
        </Document>
        <Document ID="5">
            <Title>Methods</Title>
            <Text># Methods

These are our methods
</Text>
        </Document>
        <Document ID="12">
            <Title>Body</Title>
        </Document>
        <Document ID="6">
            <Title>Discussion</Title>
            <Text># Discussion

This is our discussion
</Text>
        </Document>
        <Document ID="13">
            <Title>Acknowledgements</Title>
            <Text># Acknowledgements

This would not have been possible without ...</Text>
        </Document>
        <Document ID="7">
            <Title>References Cited</Title>
            <Text># References Cited

</Text>
        </Document>
        <Document ID="8">
            <Title>Submission Information</Title>
            <Text>Dear Karl,

Thank you for your participation in SciDataCon.  We hope you enjoyed the conference and the rest of International Data Week and that the experiences and conversations you had are still fresh and active in your minds.

Special SciDataCon 2016 Collection in the Data Science Journal
The present message is a reminder that all presenters at SciDataCon are invited to submit a paper to the Data Science Journal http://datascience.codata.org/ to be considered as part of a high-profile special collection of papers from the conference.

Please note the following:
The deadline for submissions to be part of the SciDataCon 2016 special collection has been extended to 31 October.
Submissions should be made at http://datascience.codata.org/
	•	The submission should be a full paper (please see instructions on the Data Science Journal website ), not the abstract submitted for SciDataCon.
	•	Even though an abstract was accepted for SciDataCon, the full paper submitted to the Data Science Journal will be peer-reviewed to ensure quality.
	•	Given the number of papers expected we are unable to waive the Article Processing Charge (APC) for all papers, however the Data Science Journal is very competitive and has a progressive waiver policy for those unable to pay the APC: http://datascience.codata.org/about/submissions/
Other Deadlines for Data Science Journal Collections
Two other Data Science Journal Calls for Papers are open with deadlines approaching:
 
Call for Papers: “Open Data and African Research”
This Special Issue aims to explore how, why, and to what end scientists in developing countries, and particularly those in sub-Sahara Africa, share and re-use data, and whether these activities differ from the priorities, practices, and policies associated with research in other conditions. We seek to attract papers that capture the challenges of conducting research in low-resourced environments and the innovative ways in which scientists overcome these challenges and produce/disseminate/use data (whether in digital or other formats).  We would be happy to discuss possible contributions with prospective authors over email.
 
Final deadline 20 December, but please contact the editors via s.leonelli@exeter.ac.uk as soon as possible.  Further details at http://datascience.codata.org/announcement/
 
Call for Papers: Special Issue: 20 Years Persistent Identifiers
Persistent identifiers (PID) for scholarly resources have been around now for more than 20 years. Since the initial launch of the Handle.net we have seen a proliferation of PID into many use cases. Some PID systems have become established parts of the science information infrastructure, in other areas we are seeing work in progress, and new use cases being proposed. In addition to the PID use cases a number of critical questions arise. These include:
	•	What progress has been made - what works and what lessons have we learned?
	•	Are there key gaps in the ways that research outputs are structured, accredited and exposed?
	•	How are issues of interoperability between different PID systems to be handled, and what are the implications of doing so?
	•	How do we ensure trust in PIDs and their long-term sustainability? What is the relationship between PIDs, metrics and data quality?
	•	What are the roles of the various stakeholders, e.g. funders, publishers, researchers, learned societies, repository managers?
Areas of discussion in this issue include:
	•	Usage of PIDs within and across disciplines (e.g. earth sciences, life sciences, medicine, digital humanities, cultural heritage)
	•	New use cases (e.g. provenance, dynamic data, fine-grained access, reference, credit, metrics, quality, standards)
	•	Communities of practice and governance around PID systems
	•	New forms of scholarly output, communication, linked data and business models 
The deadline is 31 October.  Please consult http://datascience.codata.org/announcement/ for further details.
 
With very best wishes, etc.
 
Asha
 
On behalf of Simon Hodson, Executive Director, CODATA
http://www.codata.org
simon@codata.org
 </Text>
        </Document>
        <Document ID="14">
            <Title>Untitled</Title>
        </Document>
        <Document ID="9">
            <Title>Abstract</Title>
            <Text># Abstract

Current research data management and curation practices can be described as falling along a continuum between highly engineered systems and ad-hoc practices. In recognition of the increasing investment in and importance of research data as an asset for doing research, evaluating current research results, and as a resource for new research, funding agencies, publishers and some research teams have instituted research data management practices aligned with a wide variety of data life cycle models that embody a circular process of steps that include such activities as creation, assessment, documentation, use, preservation, discovery and reuse. While these data lifecycle approaches are well aligned with the documentation and preservation of research data - particularly as they have been primarily developed by organizations with a mandate to provide for the preservation of data, this linear (or more appropriately cyclical) model does not necessarily focus on the level of effort required throughout the processes embodied in the lifecycle or the lowering of barriers to subsequent reuse. The agile data curation conceptual model outlined herein provides is intended to propose as a starting point for community consideration a core set of values, principles and in the long-run recommended practices in the form of research data management and curation design patterns that may be used to define project-specific activities that are likely to both meet the immediate needs of data producing research projects while also maximizing the net value of data produced by those projects for future research, education, and applications. </Text>
        </Document>
    </Documents>
</SearchIndexes>